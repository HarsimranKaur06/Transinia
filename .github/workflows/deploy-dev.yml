name: CI/CD â€” build, push to ECR, deploy to ECS (dev)

on:
  push:
    branches: [ dev ]

env:
  ENVIRONMENT: dev
  AWS_REGION: ${{ secrets.AWS_REGION }}
  AWS_ACCOUNT_ID: ${{ secrets.AWS_ACCOUNT_ID }}
  ECR_REGISTRY: ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_REGION }}.amazonaws.com
  BACKEND_ECR_REPO: transinia-dev-backend
  FRONTEND_ECR_REPO: transinia-dev-frontend
  CLUSTER_NAME: transinia-dev-cluster
  BACKEND_SERVICE: transinia-dev-backend-service
  FRONTEND_SERVICE: transinia-dev-frontend-service
  BACKEND_API_URL: http://transinia-dev-alb-1892657611.us-east-1.elb.amazonaws.com

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    permissions:
      contents: 'read'
      id-token: 'write'
    # Add always() to ensure cleanup runs even if job fails
    if: always()

    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Create ECR repositories if missing
        run: |
          aws ecr describe-repositories --repository-names $BACKEND_ECR_REPO >/dev/null 2>&1 || aws ecr create-repository --repository-name $BACKEND_ECR_REPO
          aws ecr describe-repositories --repository-names $FRONTEND_ECR_REPO >/dev/null 2>&1 || aws ecr create-repository --repository-name $FRONTEND_ECR_REPO

      - name: Login to ECR
        uses: aws-actions/amazon-ecr-login@v1
        id: ecr-login
        with:
          mask-password: 'true'

      # Set up Terraform
      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.7.5

      # Deploy DynamoDB infrastructure
      - name: Deploy DynamoDB Infrastructure
        working-directory: ./backend/infra/dynamodb-infra
        env:
          TF_VAR_environment: "dev"
          TF_VAR_dynamodb_table_meetings: ${{ secrets.DEV_DYNAMODB_TABLE_MEETINGS_BASE }}
          TF_VAR_dynamodb_table_actions: ${{ secrets.DEV_DYNAMODB_TABLE_ACTIONS_BASE }}
        run: |
          terraform init -upgrade
          terraform plan -out=dynamodb_tf.plan
          terraform apply -auto-approve dynamodb_tf.plan

      # Deploy S3 bucket infrastructure
      - name: Deploy S3 Bucket Infrastructure
        working-directory: ./backend/infra/s3-bucket-infra
        env:
          TF_VAR_environment: "dev"
          TF_VAR_s3_bucket_raw: ${{ secrets.DEV_S3_BUCKET_RAW_BASE }}
          TF_VAR_s3_bucket_processed: ${{ secrets.DEV_S3_BUCKET_PROCESSED_BASE }}
        run: |
          terraform init -upgrade
          terraform plan -out=s3_tf.plan
          terraform apply -auto-approve s3_tf.plan
      
      - name: Build and push backend image
        id: build-backend
        uses: docker/build-push-action@v4
        with:
          context: ./backend
          file: ./backend/Dockerfile
          push: true
          tags: ${{ env.ECR_REGISTRY }}/${{ env.BACKEND_ECR_REPO }}:latest

      - name: Build and push frontend image
        id: build-frontend
        uses: docker/build-push-action@v4
        with:
          context: ./frontend
          file: ./frontend/Dockerfile
          push: true
          tags: ${{ env.ECR_REGISTRY }}/${{ env.FRONTEND_ECR_REPO }}:latest
          build-args: |
            NEXT_PUBLIC_BACKEND_URL=${{ env.BACKEND_API_URL }}
            NEXT_PUBLIC_API_URL=${{ env.BACKEND_API_URL }}

      - name: Create CloudWatch Log Groups
        run: |
          echo "Creating CloudWatch Log Groups..."
          # Create log groups with explicit paths and region
          aws logs create-log-group --log-group-name "/ecs/transinia-dev-backend" --region ${{ env.AWS_REGION }} || true
          aws logs create-log-group --log-group-name "/ecs/transinia-dev-frontend" --region ${{ env.AWS_REGION }} || true
          echo "Log groups created or already exist"

      - name: Prepare backend task definition
        run: |
          # Replace placeholders in task definition
          sed -i 's#\${AWS_REGION}#${{ env.AWS_REGION }}#g' .github/ecs/taskdef-backend.json
          sed -i 's#\${ECS_EXECUTION_ROLE_ARN}#arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/transinia-dev-ecsTaskExecutionRole#g' .github/ecs/taskdef-backend.json
          sed -i 's#\${ECS_TASK_ROLE_ARN}#arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/transinia-dev-ecsTaskRole#g' .github/ecs/taskdef-backend.json
          sed -i 's#\${DYNAMODB_TABLE_MEETINGS_BASE}#${{ secrets.DEV_DYNAMODB_TABLE_MEETINGS_BASE }}#g' .github/ecs/taskdef-backend.json
          sed -i 's#\${DYNAMODB_TABLE_ACTIONS_BASE}#${{ secrets.DEV_DYNAMODB_TABLE_ACTIONS_BASE }}#g' .github/ecs/taskdef-backend.json
          sed -i 's#\${AWS_ACCESS_KEY_ID}#${{ secrets.AWS_ACCESS_KEY_ID }}#g' .github/ecs/taskdef-backend.json
          sed -i 's#\${AWS_SECRET_ACCESS_KEY}#${{ secrets.AWS_SECRET_ACCESS_KEY }}#g' .github/ecs/taskdef-backend.json
          sed -i 's#\${OPENAI_API_KEY}#${{ secrets.OPENAI_API_KEY }}#g' .github/ecs/taskdef-backend.json
          sed -i 's#\${S3_BUCKET_RAW_BASE}#${{ secrets.DEV_S3_BUCKET_RAW_BASE }}#g' .github/ecs/taskdef-backend.json
          sed -i 's#\${S3_BUCKET_PROCESSED_BASE}#${{ secrets.DEV_S3_BUCKET_PROCESSED_BASE }}#g' .github/ecs/taskdef-backend.json
          sed -i 's#\${ENVIRONMENT}#dev#g' .github/ecs/taskdef-backend.json
          
      - name: Render backend task definition
        id: deploy-backend
        uses: aws-actions/amazon-ecs-render-task-definition@v1
        with:
          task-definition: .github/ecs/taskdef-backend.json
          container-name: meeting-bot
          image: ${{ env.ECR_REGISTRY }}/${{ env.BACKEND_ECR_REPO }}:latest

      # Skip deploying to ECS directly - Terraform will handle it
      - name: Prepare frontend task definition
        run: |
          # Replace placeholders in task definition
          sed -i 's#\${AWS_REGION}#${{ env.AWS_REGION }}#g' .github/ecs/taskdef-frontend.json
          sed -i 's#\${ECS_EXECUTION_ROLE_ARN}#arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/transinia-dev-ecsTaskExecutionRole#g' .github/ecs/taskdef-frontend.json
          sed -i 's#\${ECS_TASK_ROLE_ARN}#arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/transinia-dev-ecsTaskRole#g' .github/ecs/taskdef-frontend.json
          sed -i 's#\${BACKEND_API_URL}#${{ env.BACKEND_API_URL }}#g' .github/ecs/taskdef-frontend.json
          
      - name: Render frontend task definition
        id: deploy-frontend
        uses: aws-actions/amazon-ecs-render-task-definition@v1
        with:
          task-definition: .github/ecs/taskdef-frontend.json
          container-name: frontend
          image: ${{ env.ECR_REGISTRY }}/${{ env.FRONTEND_ECR_REPO }}:latest

      # Skip deploying to ECS directly - Terraform will handle it
          
      # Check and create ECS resources if they don't exist
      - name: Create ECS cluster and services if missing
        run: |
          echo "Checking if ECS cluster exists..."
          if ! aws ecs describe-clusters --clusters ${{ env.CLUSTER_NAME }} --query "clusters[?clusterName=='${{ env.CLUSTER_NAME }}'].clusterName" --output text | grep "${{ env.CLUSTER_NAME }}"; then
            echo "Creating ECS cluster ${{ env.CLUSTER_NAME }}..."
            aws ecs create-cluster --cluster-name ${{ env.CLUSTER_NAME }}
          else
            echo "ECS cluster ${{ env.CLUSTER_NAME }} already exists."
          fi
          
          echo "Checking if backend service exists..."
          if ! aws ecs describe-services --cluster ${{ env.CLUSTER_NAME }} --services ${{ env.BACKEND_SERVICE }} --query "services[?serviceName=='${{ env.BACKEND_SERVICE }}'].serviceName" --output text | grep "${{ env.BACKEND_SERVICE }}"; then
            echo "Creating ECS service ${{ env.BACKEND_SERVICE }}..."
            aws ecs create-service --cluster ${{ env.CLUSTER_NAME }} --service-name ${{ env.BACKEND_SERVICE }} --desired-count 1 --launch-type FARGATE --platform-version LATEST --network-configuration "awsvpcConfiguration={subnets=[subnet-12345678,subnet-87654321],securityGroups=[sg-12345678],assignPublicIp=ENABLED}" --task-definition transinia-dev-backend:1
          else
            echo "ECS service ${{ env.BACKEND_SERVICE }} already exists."
          fi
          
          echo "Checking if frontend service exists..."
          if ! aws ecs describe-services --cluster ${{ env.CLUSTER_NAME }} --services ${{ env.FRONTEND_SERVICE }} --query "services[?serviceName=='${{ env.FRONTEND_SERVICE }}'].serviceName" --output text | grep "${{ env.FRONTEND_SERVICE }}"; then
            echo "Creating ECS service ${{ env.FRONTEND_SERVICE }}..."
            aws ecs create-service --cluster ${{ env.CLUSTER_NAME }} --service-name ${{ env.FRONTEND_SERVICE }} --desired-count 1 --launch-type FARGATE --platform-version LATEST --network-configuration "awsvpcConfiguration={subnets=[subnet-12345678,subnet-87654321],securityGroups=[sg-12345678],assignPublicIp=ENABLED}" --task-definition transinia-dev-frontend:1
          else
            echo "ECS service ${{ env.FRONTEND_SERVICE }} already exists."
          fi

      # Deploy ECS Fargate infrastructure
      - name: Deploy ECS Fargate Infrastructure
        working-directory: ./backend/infra/ecs-fargate-infra
        env:
          TF_VAR_environment: "dev"
          TF_VAR_aws_region: ${{ secrets.AWS_REGION }}
          TF_VAR_backend_ecr_repo: ${{ env.BACKEND_ECR_REPO }}
          TF_VAR_frontend_ecr_repo: ${{ env.FRONTEND_ECR_REPO }}
          TF_VAR_backend_image: "${{ env.ECR_REGISTRY }}/${{ env.BACKEND_ECR_REPO }}:latest"
          TF_VAR_frontend_image: "${{ env.ECR_REGISTRY }}/${{ env.FRONTEND_ECR_REPO }}:latest"
          TF_VAR_aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          TF_VAR_aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          TF_VAR_openai_api_key: ${{ secrets.OPENAI_API_KEY }}
          TF_VAR_dynamodb_table_meetings_base: ${{ secrets.DEV_DYNAMODB_TABLE_MEETINGS_BASE }}
          TF_VAR_dynamodb_table_actions_base: ${{ secrets.DEV_DYNAMODB_TABLE_ACTIONS_BASE }}
          TF_VAR_s3_bucket_raw_base: ${{ secrets.DEV_S3_BUCKET_RAW_BASE }}
          TF_VAR_s3_bucket_processed_base: ${{ secrets.DEV_S3_BUCKET_PROCESSED_BASE }}
        run: |
          terraform init -upgrade
          terraform plan -out=ecs_tf.plan
          terraform apply -auto-approve ecs_tf.plan

      # Cleanup step - always runs even if prior steps fail
      - name: Cleanup
        if: always()
        run: |
          echo "Performing cleanup operations..."
          # Double check the log groups exist
          aws logs create-log-group --log-group-name "/ecs/transinia-dev-backend" --region ${{ env.AWS_REGION }} || true
          aws logs create-log-group --log-group-name "/ecs/transinia-dev-frontend" --region ${{ env.AWS_REGION }} || true
          
          # Check for any failed tasks and stop them
          FAILED_TASKS=$(aws ecs list-tasks --cluster ${{ env.CLUSTER_NAME }} --desired-status STOPPED --query 'taskArns[*]' --output text || echo "")
          if [[ ! -z "$FAILED_TASKS" ]]; then
            echo "Cleaning up failed tasks: $FAILED_TASKS"
            for TASK in $FAILED_TASKS; do
              aws ecs stop-task --cluster ${{ env.CLUSTER_NAME }} --task $TASK --region ${{ env.AWS_REGION }} || true
            done
          fi
